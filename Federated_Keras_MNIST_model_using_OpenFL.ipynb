{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated Keras MNIST model using OpenFL",
      "provenance": [],
      "authorship_tag": "ABX9TyMUuMDVeIkdD6FB3kmdu1AJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrs2QCmjwy1z",
        "outputId": "f8202cd7-36cb-420b-b4f0-a4566616ac62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.9.1\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.15.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.1.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.47.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.26.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.9.1) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow==2.9.1) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.9.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "5cLYoTnFxM_e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openfl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qKwjbxAsx_rl",
        "outputId": "8755bd7f-6003-4bc6-840e-d204e9d3fab5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openfl\n",
            "  Downloading openfl-1.3-py3-none-any.whl (535 kB)\n",
            "\u001b[K     |████████████████████████████████| 535 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from openfl) (4.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from openfl) (1.0.2)\n",
            "Collecting docker\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openfl) (4.64.0)\n",
            "Collecting Click==8.0.1\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openfl) (2.23.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from openfl) (3.17.3)\n",
            "Collecting flatten-json\n",
            "  Downloading flatten_json-0.1.13.tar.gz (11 kB)\n",
            "Collecting rich==9.1.0\n",
            "  Downloading rich-9.1.0-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from openfl) (1.3.0)\n",
            "Collecting cryptography>=3.4.6\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 35.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openfl) (1.21.6)\n",
            "Collecting grpcio-tools~=1.34.0\n",
            "  Downloading grpcio_tools-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting dynaconf==3.1.7\n",
            "  Downloading dynaconf-3.1.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openfl) (1.3.5)\n",
            "Collecting PyYAML>=5.4.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting jupyterlab\n",
            "  Downloading jupyterlab-3.4.5-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from openfl) (2.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Click==8.0.1->openfl) (4.12.0)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting typing-extensions<4.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich==9.1.0->openfl) (2.6.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.4.6->openfl) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.4.6->openfl) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio~=1.34.0->openfl) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from grpcio-tools~=1.34.0->openfl) (57.4.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openfl) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openfl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openfl) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openfl) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Click==8.0.1->openfl) (3.8.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->openfl) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->openfl) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->openfl) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->openfl) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->openfl) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->openfl) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->openfl) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->openfl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->openfl) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->openfl) (0.2.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->openfl) (23.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->openfl) (4.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->openfl) (2.8.2)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from jupyterlab->openfl) (5.3.1)\n",
            "Collecting nbclassic\n",
            "  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab->openfl) (21.3)\n",
            "Collecting jupyter-server~=1.16\n",
            "  Downloading jupyter_server-1.18.1-py3-none-any.whl (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab->openfl) (2.11.3)\n",
            "Collecting jupyterlab-server~=2.10\n",
            "  Downloading jupyterlab_server-2.15.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting tornado>=4.0\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[K     |████████████████████████████████| 423 kB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.1->jupyterlab->openfl) (2.0.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab->openfl) (0.14.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab->openfl) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab->openfl) (1.8.0)\n",
            "Collecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab->openfl) (21.3.0)\n",
            "Collecting jupyter-client\n",
            "  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab->openfl) (5.4.0)\n",
            "Collecting nbconvert>=6.4.4\n",
            "  Downloading nbconvert-6.5.3-py3-none-any.whl (563 kB)\n",
            "\u001b[K     |████████████████████████████████| 563 kB 54.6 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->openfl) (1.5.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->openfl) (0.4)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab->openfl) (2.10.3)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab->openfl) (4.3.3)\n",
            "Collecting json5\n",
            "  Downloading json5-0.9.9-py2.py3-none-any.whl (18 kB)\n",
            "Collecting jinja2>=2.1\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab->openfl) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab->openfl) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab->openfl) (5.9.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (1.1.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (5.0.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (0.2.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (1.5.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (0.6.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (4.9.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (0.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (4.6.3)\n",
            "Collecting traitlets>=4.1.0\n",
            "  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.16->jupyterlab->openfl) (2.16.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook<7->jupyterlab->openfl) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.16->jupyterlab->openfl) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.16->jupyterlab->openfl) (21.2.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.10->jupyterlab->openfl) (2022.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab->openfl) (0.5.1)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.1.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab->openfl) (3.0.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->openfl) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->openfl) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->openfl) (1.7.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->openfl) (1.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->openfl) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openfl) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->openfl) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->openfl) (3.2.0)\n",
            "Building wheels for collected packages: flatten-json\n",
            "  Building wheel for flatten-json (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flatten-json: filename=flatten_json-0.1.13-py3-none-any.whl size=7979 sha256=8a2a76d62f0326680fa64aaabef346c1148ebdf00c4c3b41d4d05fea3dfefe26\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/b3/2a/beb2ceb72d11bf335f9c2f87aae26981f6744f3fc885cde665\n",
            "Successfully built flatten-json\n",
            "Installing collected packages: typing-extensions, traitlets, tornado, jupyter-client, sniffio, jinja2, websocket-client, nbconvert, anyio, jupyter-server, notebook-shim, json5, nbclassic, jupyterlab-server, grpcio, commonmark, colorama, tensorboardX, rich, PyYAML, jupyterlab, grpcio-tools, flatten-json, dynaconf, docker, cryptography, Click, openfl\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: Click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Click-8.0.1 PyYAML-6.0 anyio-3.6.1 colorama-0.4.5 commonmark-0.9.1 cryptography-37.0.4 docker-5.0.3 dynaconf-3.1.7 flatten-json-0.1.13 grpcio-1.34.1 grpcio-tools-1.34.1 jinja2-3.1.2 json5-0.9.9 jupyter-client-7.3.4 jupyter-server-1.18.1 jupyterlab-3.4.5 jupyterlab-server-2.15.0 nbclassic-0.4.3 nbconvert-6.5.3 notebook-shim-0.1.0 openfl-1.3 rich-9.1.0 sniffio-1.2.0 tensorboardX-2.5.1 tornado-6.2 traitlets-5.3.0 typing-extensions-3.10.0.2 websocket-client-1.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tornado",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openfl.native as fx\n",
        "from openfl.federated import FederatedModel,FederatedDataSet\n",
        "\n",
        "#importing OpenFL and it's required libraries"
      ],
      "metadata": {
        "id": "9hrPB6wAxqjU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install intel-tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DJWDtjuAy-t3",
        "outputId": "93aa1aa8-2e64-4a82-fb5a-2152b250243b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting intel-tensorflow\n",
            "  Downloading intel_tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 232.6 MB 65 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.34.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.2.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.4.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->intel-tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->intel-tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->intel-tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->intel-tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->intel-tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->intel-tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->intel-tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->intel-tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->intel-tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->intel-tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->intel-tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->intel-tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->intel-tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->intel-tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->intel-tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->intel-tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, keras, intel-tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0+zzzcolab20220506150900 requires keras<2.8,>=2.7.0rc0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow 2.7.0+zzzcolab20220506150900 requires tensorflow-estimator<2.8,~=2.7.0rc0, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed intel-tensorflow-2.9.1 keras-2.9.0 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_intel_tensorflow():\n",
        "    \"\"\"\n",
        "    Check if Intel version of TensorFlow is installed\n",
        "    \"\"\"\n",
        "    import tensorflow as tf\n",
        "\n",
        "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
        "\n",
        "    major_version = int(tf.__version__.split(\".\")[0])\n",
        "    if major_version >= 2:\n",
        "        from tensorflow.python.util import _pywrap_util_port\n",
        "        print(\"Intel-optimizations (DNNL) enabled:\",\n",
        "              _pywrap_util_port.IsMklEnabled())\n",
        "    else:\n",
        "        print(\"Intel-optimizations (DNNL) enabled:\")\n",
        "\n",
        "test_intel_tensorflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5RKNaMuyzoq",
        "outputId": "b010c9ef-890f-4f00-dab6-17ae87c9ef4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using Tensorflow version 2.9.1\n",
            "Intel-optimizations (DNNL) enabled: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fx.init('keras_cnn_mnist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sWWIhuUxylV",
        "outputId": "b4c49884-290e-479e-c22f-5a828101c698"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Workspace Directories\n",
            "Creating Workspace Templates\n",
            "Successfully installed packages from /root/.local/workspace/requirements.txt.\n",
            "\n",
            "New workspace directory structure:\n",
            "workspace\n",
            "├── cert\n",
            "├── plan\n",
            "│   ├── data.yaml\n",
            "│   ├── defaults\n",
            "│   ├── cols.yaml\n",
            "│   └── plan.yaml\n",
            "├── src\n",
            "│   ├── keras_cnn.py\n",
            "│   ├── mnist_utils.py\n",
            "│   ├── __init__.py\n",
            "│   └── tfmnist_inmemory.py\n",
            "├── logs\n",
            "├── .workspace\n",
            "├── save\n",
            "├── data\n",
            "└── requirements.txt\n",
            "\n",
            "6 directories, 10 files\n",
            "Setting Up Certificate Authority...\n",
            "\n",
            "1.  Create Root CA\n",
            "1.1 Create Directories\n",
            "1.2 Create Database\n",
            "1.3 Create CA Request and Certificate\n",
            "2.  Create Signing Certificate\n",
            "2.1 Create Directories\n",
            "2.2 Create Database\n",
            "2.3 Create Signing Certificate CSR\n",
            "2.4 Sign Signing Certificate CSR\n",
            "3   Create Certificate Chain\n",
            "\n",
            "Done.\n",
            "Creating AGGREGATOR certificate key pair with following settings: CN=\u001b[31m187c9ce15195\u001b[0m, SAN=\u001b[31mDNS:187c9ce15195\u001b[0m\n",
            "  Writing AGGREGATOR certificate key pair to: \u001b[32m/content/cert/server\u001b[0m\n",
            "The CSR Hash for file \u001b[32mserver/agg_187c9ce15195.csr\u001b[0m = \u001b[31mdf50cd64f952b62c286a3f17ae2f893a30aa327129458af05071cda11475f29b2fe22eb7356882dd0aaa9261bc8b27a6\u001b[0m\n",
            " Signing AGGREGATOR certificate\n",
            "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mone\u001b[0m, SAN=\u001b[31mDNS:one\u001b[0m\n",
            "  Moving COLLABORATOR certificate to: \u001b[32m/content/cert/col_one\u001b[0m\n",
            "The CSR Hash for file \u001b[32mcol_one.csr\u001b[0m = \u001b[31m26b79638f23ae15190c486d40198dce225d1178c88981a5a80ff5d39f3eb045bd711787bbd910bb3e273cb01cd334b33\u001b[0m\n",
            " Signing COLLABORATOR certificate\n",
            "\n",
            "Registering \u001b[32mone\u001b[0m in \u001b[32m/root/.local/workspace/plan/cols.yaml\u001b[0m\n",
            "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mtwo\u001b[0m, SAN=\u001b[31mDNS:two\u001b[0m\n",
            "  Moving COLLABORATOR certificate to: \u001b[32m/content/cert/col_two\u001b[0m\n",
            "The CSR Hash for file \u001b[32mcol_two.csr\u001b[0m = \u001b[31m850b468c56a69d4776c03fd645239ff2e97348a2b2508be0f0bd0e9d6efef3d453d7aa51acc7a97f2626370fb31e394e\u001b[0m\n",
            " Signing COLLABORATOR certificate\n",
            "\n",
            "Registering \u001b[32mtwo\u001b[0m in \u001b[32m/root/.local/workspace/plan/cols.yaml\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' After importing the required packages, we then setup our openfl workspace. fx.init() command is used\n",
        "to setup a deafult workspace.\n",
        "'''"
      ],
      "metadata": {
        "id": "ffIVOOwTyXz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to define our datatset and model to perform federated learning on it. We will start with a fully connected model that is trained on the MNIST dataset."
      ],
      "metadata": {
        "id": "a9ijEGIrzZfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import and process training, validation, and test images/labels\n",
        "\n",
        "# Set the ratio of validation imgs, can't be 0.0\n",
        "VALID_PERCENT = 0.3\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "split_on = int((1 - VALID_PERCENT) * len(X_train))\n",
        "\n",
        "train_images = X_train[0:split_on,:,:]\n",
        "train_labels = to_categorical(y_train)[0:split_on,:]\n",
        "\n",
        "valid_images = X_train[split_on:,:,:]\n",
        "valid_labels = to_categorical(y_train)[split_on:,:]\n",
        "\n",
        "test_images = X_test\n",
        "test_labels = to_categorical(y_test)\n",
        "\n",
        "def preprocess(images):\n",
        "    #Normalize\n",
        "    images = (images / 255) - 0.5\n",
        "    #Flatten\n",
        "    images = images.reshape((-1, 784))\n",
        "    return images\n",
        "\n",
        "# Preprocess the images.\n",
        "train_images = preprocess(train_images)\n",
        "valid_images = preprocess(valid_images)\n",
        "test_images = preprocess(test_images)\n",
        "\n",
        "feature_shape = train_images.shape[1]\n",
        "classes = 10\n",
        "\n",
        "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
        "\n",
        "def build_model(feature_shape,classes):\n",
        "    #Defines the MNIST model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=feature_shape, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(classes, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'],)\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T7W0gTrzVNk",
        "outputId": "245aace0-b1e1-41e4-83fe-804f7b1359f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' The code starts by importing the MNIST dataset. It then splits the images into training and validation\n",
        "sets, using the ratio of 0.3 for validation images.\n",
        "\n",
        "The code then loads the data and preprocesses it to \n",
        "make sure that all feaures are normalized beofre building a ML model with a single hidden layer of 64 \n",
        "nerurons with relu (rectified linear) activation function.\n",
        "This activation function will give the output as input directly if it is positie otherwise the output will\n",
        "be zero.\n",
        "\n",
        "The code then defines a model which has one input layer and two dense layers. The first dense layer is used\n",
        "as input to the second dense layer which is used as an input to the softmax activation function.\n",
        "\n",
        "The code the finally builds a model for the MNIST dataset.\n",
        "'''"
      ],
      "metadata": {
        "id": "cC5a2FJXztE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a federated model using the build model function and dataset\n",
        "fl_model = FederatedModel(build_model,data_loader=fl_data)"
      ],
      "metadata": {
        "id": "Ys2GVHdL1h1n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FederatedModel object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's setup function, collaborator models and datasets can be automatically defined for the experiment."
      ],
      "metadata": {
        "id": "hIQmYiop17YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collaborator_models = fl_model.setup(num_collaborators=2)\n",
        "collaborators = {'one':collaborator_models[0],'two':collaborator_models[1]}\n",
        "#, 'three':collaborator_models[2]}\n",
        "\n",
        "#the code creates two models for the two collaborators."
      ],
      "metadata": {
        "id": "SDpiX3Ah1jHQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Original MNIST dataset\n",
        "print(f'Original training data size: {len(train_images)}')\n",
        "print(f'Original validation data size: {len(valid_images)}\\n')\n",
        "\n",
        "#Collaborator one's data\n",
        "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
        "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
        "\n",
        "#Collaborator two's data\n",
        "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
        "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
        "\n",
        "#Collaborator three's data\n",
        "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
        "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LX0Nclj2GBg",
        "outputId": "3c0cd211-8dbe-4f5e-a0f4-2cdb41bd01c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training data size: 42000\n",
            "Original validation data size: 18000\n",
            "\n",
            "Collaborator one's training data size: 21000\n",
            "Collaborator one's validation data size: 9000\n",
            "\n",
            "Collaborator two's training data size: 21000\n",
            "Collaborator two's validation data size: 9000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the current values of the plan. Each of these can be overridden\n",
        "print(fx.get_plan())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt0_kLbj2kRP",
        "outputId": "d855450a-9cbf-4c58-dd57-745fdb356e16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"aggregator.settings.best_state_path\": \"save/keras_cnn_mnist_best.pbuf\",\n",
            "    \"aggregator.settings.db_store_rounds\": 2,\n",
            "    \"aggregator.settings.init_state_path\": \"save/keras_cnn_mnist_init.pbuf\",\n",
            "    \"aggregator.settings.last_state_path\": \"save/keras_cnn_mnist_last.pbuf\",\n",
            "    \"aggregator.settings.rounds_to_train\": 10,\n",
            "    \"aggregator.settings.write_logs\": false,\n",
            "    \"aggregator.template\": \"openfl.component.Aggregator\",\n",
            "    \"assigner.settings.task_groups\": [\n",
            "        {\n",
            "            \"name\": \"train_and_validate\",\n",
            "            \"percentage\": 1.0,\n",
            "            \"tasks\": [\n",
            "                \"aggregated_model_validation\",\n",
            "                \"train\",\n",
            "                \"locally_tuned_model_validation\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"assigner.template\": \"openfl.component.RandomGroupedAssigner\",\n",
            "    \"collaborator.settings.db_store_rounds\": 1,\n",
            "    \"collaborator.settings.delta_updates\": false,\n",
            "    \"collaborator.settings.opt_treatment\": \"RESET\",\n",
            "    \"collaborator.template\": \"openfl.component.Collaborator\",\n",
            "    \"compression_pipeline.settings\": {},\n",
            "    \"compression_pipeline.template\": \"openfl.pipelines.NoCompressionPipeline\",\n",
            "    \"data_loader.settings.batch_size\": 256,\n",
            "    \"data_loader.settings.collaborator_count\": 2,\n",
            "    \"data_loader.settings.data_group_name\": \"mnist\",\n",
            "    \"data_loader.template\": \"src.tfmnist_inmemory.TensorFlowMNISTInMemory\",\n",
            "    \"network.settings.agg_addr\": \"187c9ce15195\",\n",
            "    \"network.settings.agg_port\": 50263,\n",
            "    \"network.settings.cert_folder\": \"cert\",\n",
            "    \"network.settings.client_reconnect_interval\": 5,\n",
            "    \"network.settings.disable_client_auth\": false,\n",
            "    \"network.settings.hash_salt\": \"auto\",\n",
            "    \"network.settings.tls\": true,\n",
            "    \"network.template\": \"openfl.federation.Network\",\n",
            "    \"task_runner.settings\": {},\n",
            "    \"task_runner.template\": \"src.keras_cnn.KerasCNN\",\n",
            "    \"tasks.aggregated_model_validation.function\": \"validate\",\n",
            "    \"tasks.aggregated_model_validation.kwargs\": {\n",
            "        \"apply\": \"global\",\n",
            "        \"batch_size\": 32,\n",
            "        \"metrics\": [\n",
            "            \"accuracy\"\n",
            "        ]\n",
            "    },\n",
            "    \"tasks.locally_tuned_model_validation.function\": \"validate\",\n",
            "    \"tasks.locally_tuned_model_validation.kwargs\": {\n",
            "        \"apply\": \"local\",\n",
            "        \"batch_size\": 32,\n",
            "        \"metrics\": [\n",
            "            \"accuracy\"\n",
            "        ]\n",
            "    },\n",
            "    \"tasks.settings\": {},\n",
            "    \"tasks.train.function\": \"train\",\n",
            "    \"tasks.train.kwargs\": {\n",
            "        \"batch_size\": 32,\n",
            "        \"epochs\": 1,\n",
            "        \"metrics\": [\n",
            "            \"loss\"\n",
            "        ]\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the override_config parameter"
      ],
      "metadata": {
        "id": "ja0uJRWa2rRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run experiment, return trained FederatedModel\n",
        "final_fl_model = fx.run_experiment(collaborators,override_config={'aggregator.settings.rounds_to_train':5})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9QlABVn2nvf",
        "outputId": "4e433cd9-0c58-4092-fe62-755f31b983b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282/282 [==============================] - 2s 4ms/step - loss: 2.3616 - accuracy: 0.0882\n",
            "657/657 [==============================] - 3s 3ms/step - loss: 0.5553 - accuracy: 0.8321\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.3171 - accuracy: 0.9026\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 2.3623 - accuracy: 0.0820\n",
            "657/657 [==============================] - 3s 3ms/step - loss: 0.5290 - accuracy: 0.8419\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.9042\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.3859 - accuracy: 0.8890\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.3089 - accuracy: 0.9080\n",
            "282/282 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.9072\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.3920 - accuracy: 0.8890\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.2987 - accuracy: 0.9099\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9187\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.2442 - accuracy: 0.9254\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.2388 - accuracy: 0.9263\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9438\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.2587 - accuracy: 0.9218\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.2275 - accuracy: 0.9287\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.2327 - accuracy: 0.9290\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1915 - accuracy: 0.9439\n",
            "657/657 [==============================] - 2s 4ms/step - loss: 0.2018 - accuracy: 0.9375\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1911 - accuracy: 0.9414\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.2027 - accuracy: 0.9392\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.1877 - accuracy: 0.9421\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.2242 - accuracy: 0.9338\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9523\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.1736 - accuracy: 0.9460\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1680 - accuracy: 0.9482\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9444\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.1639 - accuracy: 0.9509\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 0.1763 - accuracy: 0.9489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save final model and load into keras\n",
        "final_fl_model.save_native('final_model')\n",
        "model = tf.keras.models.load_model('./final_model')"
      ],
      "metadata": {
        "id": "hROD5wGa2uX0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the final model on our test set\n",
        "model.evaluate(test_images,test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCv6Je4f3DsB",
        "outputId": "7915df4f-b124-48f9-8085-1d6ca5a27af7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14210066199302673, 0.9549999833106995]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1TOcBPcW3F0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}